# Papers-list-based-mainly-on-Arxiv

## LLM
## Diffusion-Cot
### 2025
| Title  |  Conference/Journal          | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|
| Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models |  | [pdf](https://arxiv.org/pdf/2505.10446) |    | 


## 
### 2025
| Title  |  Conference/Journal          | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|
| PENCIL: Long Thoughts with Short Memory  |  | [pdf](https://arxiv.org/pdf/2503.14337) | [code](https://github.com/chr26195/PENCIL)   | 
| G |  | [pdf] | [code]   | 


## Time Scaling
### 2025
| Title  |  Conference/Journal          | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|
| TTRL: Test-Time Reinforcement Learning  |  | [pdf](https://arxiv.org/pdf/2504.16084) | [code](https://github.com/PRIME-RL/TTRL)   | 


## Long CoT
### 2025
| Title  |  Conference/Journal          | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|
| Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones  |  | [pdf](https://arxiv.org/pdf/2505.21825) | [code](https://github.com/seyedparsa/let-me-think)   |
| Demystifying Long Chain-of-Thought Reasoning in LLMs  |  | [pdf](https://arxiv.org/pdf/2502.03373) | [code](https://github.com/eddycmu/demystify-long-cot)   |



## Intrinsic
| Title  |  Conference/Journal          | Year      | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|:-------:|
| On the Biology of a Large Language Model  |  | 2025 | [pdf](https://transformer-circuits.pub/2025/attribution-graphs/biology.html) |    | 
| Alignment faking in large language models  | CoRR | 2024 | [pdf](https://arxiv.org/pdf/2412.14093v2) |    | 
| Language Models Donâ€™t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting  | NeurIPS | 2023 | [pdf](https://arxiv.org/pdf/2412.14093v2) |    | 


## Interpret
| Title  |  Conference/Journal          | Year      | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|:-------:|
| The Urgency of Interpretability  |  | 2025 | [pdf](https://www.darioamodei.com/post/the-urgency-of-interpretability) |    | 


## Optimization
| Title  |  Conference/Journal          | Year      | Pdf      | Code      | 
|:-----------------------------------------------------------------------------------:|:-----------:|:-------:|:-------:|:-------:|
| DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models  |  | 2024 | [pdf](https://arxiv.org/pdf/2402.03300) |  [code](https://github.com/deepseek-ai/DeepSeek-Math/tree/main)  | 
